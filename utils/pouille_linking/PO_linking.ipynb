{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac7386",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from lxml import etree\n",
    "import re\n",
    "from thefuzz import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a048358",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ouverture du fichier XML grâce à etree\n",
    "\n",
    "xml_file = '../../data/PO_t7/PO_t7.xml'\n",
    "xml_tree = etree.parse(xml_file)\n",
    "\n",
    "data = []\n",
    "\n",
    "#on s'occupe des vedettes: pour l'instant, notre code ne prend pas en compte les vedettes avec + d'une valeur. A voir\n",
    "#si il faut changer ça. sur le xpath cependant, on dirait qu'il n'y en a pas ?\n",
    "for article in xml_tree.xpath('//article'):\n",
    "\n",
    "#on enleve les localisationpa : inutiles pour nous si on ne se focalise que sur la france.\n",
    "        if article.find('./localisationpa') is not None:\n",
    "             continue\n",
    "        vedette_i = article.xpath('./vedette/i')\n",
    "        vedette_text = vedette_i[0].text if vedette_i else ''\n",
    "\n",
    "#pareil: il y a un seul localisationde en double, mais il ne le prend pas en compte. A voir si il faut changer ça\n",
    "        localisationde = article.find('./localisationde')\n",
    "        localisationde_text = localisationde.text if localisationde is not None else 'none'\n",
    "\n",
    "#idem. autre version du code qui en prend deux et sépare par ',' existe, à voir si c'est vraiment pertinent.\n",
    "        localisationca = article.find('./localisationca')\n",
    "        if localisationca is not None:\n",
    "            localisationca_text = re.search(r'<localisationca>(.*?)<\\/localisationca>', etree.tostring(localisationca, encoding=str)).group(1)\n",
    "            '''\n",
    "            cases:\n",
    "                - 'c<sup>on</sup> de '\n",
    "                - 'c<sup>on</sup> du '\n",
    "                - 'c<sup>on</sup> d’'\n",
    "                - 'c<sup>on</sup> de la '\n",
    "                - 'c<sup>on</sup> de l’'\n",
    "                - 'c<sup>on</sup> des '\n",
    "            '''\n",
    "            localisationca_text = re.sub(r\"c<sup>on</sup> (de |d’|de la |du |de l’|des )\", '', localisationca_text)\n",
    "            \n",
    "        else:\n",
    "            localisationca_text = 'none'\n",
    "\n",
    "#idem. Il n'y en a qu'un avec + d'une localisation -> l'autre étant en suisse. Utile ou pas? à voir.\n",
    "        localisationco = article.find('./localisationco')\n",
    "        if localisationco is not None:\n",
    "            localisationco_text = re.search(r'<localisationco>(.*?)<\\/localisationco>', etree.tostring(localisationco, encoding=str)).group(1)            \n",
    "            '''\n",
    "            cases:\n",
    "                - 'c<sup>on</sup> de '\n",
    "                - 'c<sup>on</sup> du '\n",
    "                - 'c<sup>on</sup> d’'\n",
    "                - 'c<sup>on</sup> de la '\n",
    "                - 'c<sup>on</sup> de l’'\n",
    "                - 'c<sup>on</sup> des '\n",
    "                - 'c<sup>nes</sup> de '\n",
    "                - 'c<sup>nes</sup> d’'\n",
    "            '''\n",
    "            localisationco_text = re.sub(r\"c<sup>ne(s)?</sup> (de |d’|de la |du |de l’|des )\", '', localisationco_text)\n",
    "            \n",
    "        else: \n",
    "            localisationco_text = 'none'\n",
    "    \n",
    "#on insère tout dans un dictionnaire        \n",
    "        data.append({\n",
    "            'old-id': article.get('old-id'),\n",
    "            'vedette': vedette_text,\n",
    "            'localisationde': localisationde_text,\n",
    "            'localisationca': localisationca_text,\n",
    "            'localisationco': localisationco_text\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8d5212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tous les articles dans un df\n",
    "df = pd.DataFrame(data)\n",
    "df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a723e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout du dpt code au df\n",
    "departements_df = pd.read_csv('departements-region.csv')\n",
    "\n",
    "# On crée un dictionnaire avec les éléments qui nous intéressent de notre spreadsheet des départements\n",
    "departements_dict = dict(zip(departements_df['dep_name'], departements_df['num_dep']))\n",
    "\n",
    "# on ajoute notre colonne avec les numéros des départements qui matchent\n",
    "df['num_dep'] = df['localisationde'].apply(lambda x: departements_dict.get(x, 'none'))\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df19efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on renomme pour plus de clarté.\n",
    "\n",
    "df = df.rename(columns={'old-id' : 'article_id', 'localisationca' : 'canton_code', 'localisationco_present' : 'nom_commune', 'num_dep' : 'dpt_code'})\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9fa47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pour encore plus de clarté, nous réorganisons les colonnes \n",
    "\n",
    "df = df[['article_id', 'vedette', 'localisationde', 'dpt_code', 'canton_code', 'localisationco']]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539680c0",
   "metadata": {},
   "source": [
    "## Liage des articles de type commune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169ad193",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des articles de type commune\n",
    "\n",
    "commune_df = df[df['localisationco'] == 'none']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3822c14c",
   "metadata": {},
   "source": [
    "## Liage des communes de localisation (article dans une commune)\n",
    "\n",
    "Il s’agit des lieux à l’échelle infra-communale. Ces lieux sont localisés dans une commune (`localisationco`)\n",
    "…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bf1656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liage des articles localisés dans une commune\n",
    "\n",
    "localisationco_df = df[df['localisationco'] != 'none']\n",
    "localisationco_df['dpt_code'] = localisationco_df['dpt_code'].apply(lambda x: 'DEP_' + str(x) if x != 'none' else x)\n",
    "localisationco_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba2b453",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On lie notre dataframe au référentiel insee avec de l'exact match.\n",
    "\n",
    "main_insee_commune = pd.read_csv(\"main_insee_commune.tsv\", delimiter='\\t')\n",
    "\n",
    "# on utilise merge pour le liage avec dpt_code et dep_id\n",
    "merged_df = pd.merge(filtered_df, main_insee_commune, left_on='dpt_code', right_on='DEP_id', how='left')\n",
    "\n",
    "# on sélectionne les lignes où la colonne 'localisationco' correspond à la colonne 'NCCENR' de main_insee_commune\n",
    "# exact match\n",
    "matching_rows = merged_df.loc[merged_df['localisationco'] == merged_df['NCCENR']]\n",
    "\n",
    "# on crée une colonne 'insee_code' dans le dataframe filtered_df avec les codes correspondants à partir de main_insee_commune\n",
    "filtered_df['insee_code'] = filtered_df.apply(lambda row: main_insee_commune.loc[main_insee_commune['NCCENR'] == row['localisationco']]['insee_code'].values[0] if len(main_insee_commune.loc[main_insee_commune['NCCENR'] == row['localisationco']]['insee_code'].values) > 0 else None, axis=1)\n",
    "filtered_df['insee_code'] = filtered_df['insee_code'].fillna('none')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbde918",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f59e240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vérifier les communes de localisation liées sur exact match\n",
    "# revoir commune\n",
    "\n",
    "commune = filtered_df[filtered_df['insee_code'] != 'none']\n",
    "commune.head(10)\n",
    "\n",
    "#on a donc exactement 556 matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb730b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#modification de notre dataframe: ajout d'une colonne method qui nous permet d'identifier la méthode utilisée pour le\n",
    "#liage\n",
    "\n",
    "commune['method'] = 'exact'\n",
    "# marquer les liages exécutés sans possibilité de désambiguiser le dpt (pour validation manuelle a posteriori)\n",
    "commune.loc[commune['dpt_code'] == 'none', 'method'] = 'nodpt'\n",
    "\n",
    "print(commune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce0bd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#les articles qui du coup n'ont pas de liage. on fera le fuzzy pour eux.\n",
    "\n",
    "pascommune = filtered_df.loc[filtered_df['insee_code'] == 'none']\n",
    "print(pascommune)\n",
    "\n",
    "#nous en avons donc 124."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4181379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Définition d'une fonction pour le fuzzy join\n",
    "## TODO insert NCCENR des candidats retournés par la fc fuzzy ?\n",
    "## Mettre à jour cette fonction pour définir le ration Levenshtein appliqué ?\n",
    "\n",
    "def fuzzy_join(row):\n",
    "    # Filtre sur les lignes avec les mêmes départements\n",
    "    main_dep = main_insee_commune[main_insee_commune['DEP_id'] == row['dpt_code']]\n",
    "    # Calcul de la distance Levenshtein entre la vedette du pascommune et les NCCENR de chaque ligne de main_dep\n",
    "    scores = main_dep['NCCENR'].apply(lambda x: fuzz.token_sort_ratio(x, row['vedette']))\n",
    "    # Récupération des lignes avec une distance Levenshtein inférieure ou égale à 1\n",
    "    filtered = main_dep[scores >= 90]\n",
    "    # Ajout de la colonne insee_code dans le dataframe pascommune\n",
    "    if not filtered.empty:\n",
    "        insee_code = filtered['insee_code'].values[0]\n",
    "        if pd.isnull(insee_code):\n",
    "            return 'none'\n",
    "        else:\n",
    "            return insee_code\n",
    "    else:\n",
    "        return 'none'\n",
    "\n",
    "\n",
    "# Application de la fonction sur chaque ligne du dataframe pascommune\n",
    "pascommune['insee_code'] = pascommune.apply(fuzzy_join, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb2c144",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pascommune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cecaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on veut savoir combien ont été joined par le fuzzy\n",
    "\n",
    "fuzzy = pascommune[pascommune['insee_code'] != 'none']\n",
    "\n",
    "# on ajoute une colonne method pour indiquer que le join a été réalisé par fuzzy\n",
    "\n",
    "fuzzy['method'] = 'fuzzy'\n",
    "\n",
    "\n",
    "print(fuzzy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837427c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maintenant, on s'intéresse aux localisationco qui n'ont toujours pas de liage.\n",
    "\n",
    "fuzzynull = pascommune[pascommune['insee_code'] == 'none']\n",
    "\n",
    "#idem, on ajoute la méthode pour savoir que ces derniers n'ont été matchés ni avec le exact ni avec le fuzzy\n",
    "\n",
    "fuzzynull['method'] = 'nulle'\n",
    "print(fuzzynull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6bbe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#il faut maintenant concaténer nos 3 dataframes, en respectant l'ordre original des article_id\n",
    "\n",
    "merged_df = pd.concat([commune, fuzzy, fuzzynull], axis=0)\n",
    "merged_df = merged_df.sort_values('method', ascending=True)\n",
    "\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4ceb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['origine'] = 'avecloc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f65b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"dataframe_avecloc_po7.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc66aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d309ff6",
   "metadata": {},
   "source": [
    "## Fusion et ordonnancement des liages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be43db7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
