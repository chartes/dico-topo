{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a541d55",
   "metadata": {},
   "source": [
    "# Liage entre dicotopo et le pouillé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12020b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On importe nos dataframes nécessaires à la réinjection\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import pyexcel_ods\n",
    "from unidecode import unidecode\n",
    "\n",
    "#On importe les différents fichiers nécessaires. \n",
    "\n",
    "place_old_label = pd.read_csv('../../utils/pouille/resources/place_old_label.tsv', sep='\\t', dtype=str)\n",
    "places = pd.read_csv('../../utils/pouille/resources/place.tsv', sep='\\t', dtype=str)\n",
    "liage_po7 = pd.read_csv('../../utils/pouille/out/linking_out/liage_po7.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726ca238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On applique la fonction voulue par Olivier pour supprimer les accents etc\n",
    "\n",
    "def replace_special_characters(text):\n",
    "    text = unidecode(text)\n",
    "    text = re.sub(r'[-\\']', ' ', text)\n",
    "    return text\n",
    "\n",
    "liage_po7['vedette'] = liage_po7['vedette'].astype(str)\n",
    "places['label'] = places['label'].astype(str)\n",
    "\n",
    "liage_po7['vedette'] = liage_po7['vedette'].apply(replace_special_characters)\n",
    "places['label'] = places['label'].apply(replace_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898cadab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne garde que les départements utiles à notre liage\n",
    "\n",
    "dpt_list = liage_po7['dpt_code'].unique().tolist()\n",
    "dpt_list.remove(\"none\")\n",
    "dpt_list.sort()\n",
    "print(dpt_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c89315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe à charger\n",
    "liages_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec86f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop_po = ['localisationde', 'dpt_code', 'canton_code', 'method', 'reference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f22449",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop_places = ['dpt', 'country', 'localization_commune_relation_type', 'responsibility_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des articles de type commune (ceux qui n’ont pas de commune de localisation)\n",
    "\n",
    "communes_df = liage_po7[liage_po7['localisationco'] == 'none']\n",
    "communes_df = communes_df.drop(columns=columns_to_drop_po)\n",
    "places = places.drop(columns=columns_to_drop_places)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b880f7",
   "metadata": {},
   "source": [
    "# Communes exact match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcaa012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on lie par exact match vedette / label\n",
    "\n",
    "#on enlève les lignes sans insee_code de liage_po7: elles ne servent à rien\n",
    "communes_df_nonan = communes_df.dropna(subset=['insee_code'])\n",
    "\n",
    "liage_exact_communes = pd.merge(communes_df_nonan,\n",
    "                      places,\n",
    "                      how='inner',\n",
    "                      left_on=['insee_code','vedette'],\n",
    "                      right_on=['commune_insee_code', 'label'])\n",
    "\n",
    "\n",
    "# Check for duplicate entries\n",
    "duplicates = liage_exact_communes.duplicated(['article_id'], keep=False)\n",
    "if duplicates.any():\n",
    "    liage_exact_communes = liage_exact_communes[~duplicates]\n",
    "    \n",
    "# Add a 'method' column with value 'dpt_exact'\n",
    "liage_exact_communes['method_dicotopo'] = 'communes_exact'\n",
    "\n",
    "\n",
    "# Update the linked_places_df dataframe\n",
    "liages_df = pd.concat([liages_df, liage_exact_communes]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf258d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "liages_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b5fd6",
   "metadata": {},
   "source": [
    "# Lieux dans des communes exact match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6022fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des articles appartenant à une commune (ceux ont une commune de localisation)\n",
    "\n",
    "localisationco_df = liage_po7[liage_po7['localisationco'] != 'none']\n",
    "localisationco_df = localisationco_df.drop(columns=columns_to_drop_po)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be773dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on lie par exact match vedette de la localisationco / label\n",
    "\n",
    "#on enlève les lignes sans insee_code de liage_po7: elles ne servent à rien\n",
    "localisationco_df_nonan = localisationco_df.dropna(subset=['insee_code'])\n",
    "\n",
    "liage_exact_localisationco = pd.merge(localisationco_df_nonan,\n",
    "                      places,\n",
    "                      how='inner',\n",
    "                      left_on=['insee_code','vedette'],\n",
    "                      right_on=['localization_commune_insee_code', 'label'])\n",
    "\n",
    "\n",
    "# Check for duplicate entries\n",
    "duplicates = liage_exact_localisationco.duplicated(['article_id'], keep=False)\n",
    "if duplicates.any():\n",
    "    liage_exact_localisationco = liage_exact_localisationco[~duplicates]\n",
    "    \n",
    "# Add a 'method' column with value 'dpt_exact'\n",
    "liage_exact_localisationco['method_dicotopo'] = 'localisationco_exact'\n",
    "\n",
    "\n",
    "# Update the linked_places_df dataframe\n",
    "liages_df = pd.concat([liages_df, liage_exact_localisationco]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a5a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "liages_df.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9e910",
   "metadata": {},
   "source": [
    "# Fuzzy match communes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0c96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import difflib\n",
    "\n",
    "communes_df_nonan = communes_df_nonan[~communes_df_nonan.article_id.isin(liages_df['article_id'])]\n",
    "\n",
    "liage_fuzzy_communes = pd.merge(communes_df_nonan,\n",
    "                                places,\n",
    "                                how='inner',\n",
    "                                left_on=['insee_code'],\n",
    "                                right_on=['commune_insee_code'])\n",
    "\n",
    "\n",
    "def partial_match(row):\n",
    "    vedette = row['vedette']\n",
    "    label = row['label']\n",
    "\n",
    "    if isinstance(vedette, str) and not pd.isnull(vedette) and isinstance(label, str) and not pd.isnull(label):\n",
    "        words = vedette.split()\n",
    "        if any(difflib.get_close_matches(word, label.split(), n=1) for word in words):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "liage_fuzzy_communes = liage_fuzzy_communes[liage_fuzzy_communes.apply(partial_match, axis=1)]\n",
    "\n",
    "# Add a 'method' column with value 'dicotopo_fuzzy'\n",
    "liage_fuzzy_communes['method_dicotopo'] = 'communes_fuzzy'\n",
    "\n",
    "# Update the linked_places_df dataframe\n",
    "liages_df = pd.concat([liages_df, liage_fuzzy_communes]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a67d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "liage_fuzzy_communes.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44bab95",
   "metadata": {},
   "source": [
    "# Fuzzy match localisationco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05daa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import difflib\n",
    "\n",
    "localisationco_df_nonan = localisationco_df_nonan[~localisationco_df_nonan.article_id.isin(liages_df['article_id'])]\n",
    "\n",
    "liage_fuzzy_localisationco = pd.merge(localisationco_df_nonan,\n",
    "                                places,\n",
    "                                how='inner',\n",
    "                                left_on=['insee_code'],\n",
    "                                right_on=['localization_commune_insee_code'])\n",
    "\n",
    "\n",
    "def partial_match(row):\n",
    "    vedette = row['vedette']\n",
    "    label = row['label']\n",
    "\n",
    "    if isinstance(vedette, str) and not pd.isnull(vedette) and isinstance(label, str) and not pd.isnull(label):\n",
    "        words = vedette.split()\n",
    "        if any(difflib.get_close_matches(word, label.split(), n=1) for word in words):\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "liage_fuzzy_localisationco = liage_fuzzy_localisationco[liage_fuzzy_localisationco.apply(partial_match, axis=1)]\n",
    "\n",
    "# Add a 'method' column with value 'dicotopo_fuzzy'\n",
    "liage_fuzzy_localisationco['method_dicotopo'] = 'localisationco_fuzzy'\n",
    "\n",
    "# Update the linked_places_df dataframe\n",
    "liages_df = pd.concat([liages_df, liage_fuzzy_localisationco]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e7333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "liage_fuzzy_localisationco.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ae569",
   "metadata": {},
   "source": [
    "# Exportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf80647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on append les deux dataframes ensemble\n",
    "\n",
    "new_rows_df = liage_po7[~liage_po7['article_id'].isin(liages_df['article_id'])]\n",
    "\n",
    "if 'method_dicotopo' not in new_rows_df.columns:\n",
    "    new_rows_df['method_dicotopo'] = 'nulle'\n",
    "\n",
    "liages_df = liages_df.append(new_rows_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6904cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "liages_df.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d46d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on ajoute les lignes de notre pouillé qui n'ont pas eu de match avec dicotopo pour vérification manuelle\n",
    "\n",
    "remaining_rows = liage_po7[~liage_po7['article_id'].isin(liages_df['article_id'])]\n",
    "updated_liages_df = pd.concat([liages_df, remaining_rows], ignore_index=True)\n",
    "\n",
    "#on sort par article_id pour plus de clarté\n",
    "updated_liages_df = updated_liages_df.sort_values('article_id')\n",
    "updated_liages_df = updated_liages_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645695f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_liages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b5cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_liages_df.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48745548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le dataframe fusionné\n",
    "updated_liages_df.to_csv('../../utils/pouille/out/reinjection_out/po7_dicotopo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c61861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcae589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992d1e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781b7d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94ebb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#partie pour plus tard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c6b550",
   "metadata": {},
   "source": [
    "# Réinsertion dans le fichier XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier XML\n",
    "tree = ET.parse('../../utils/pouille/out/linking_out/PO_t7_modified.xml')\n",
    "root = tree.getroot()\n",
    "# Replace nan values with empty string in the DataFrame (juste pour le temps où olivier corrige)\n",
    "liages_df = liages_df.replace({np.nan: \"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour chaque article dans le XML\n",
    "for article in root.findall('article'):\n",
    "    # Récupérer l'article_id\n",
    "    article_id = article.get('old-id')\n",
    "\n",
    "    # Vérifier si l'article_id est présent dans le DataFrame\n",
    "    if article_id in liages_df['article_id'].values:\n",
    "        # Récupérer la ligne correspondante dans le DataFrame\n",
    "        liage_row = liages_df.loc[liages_df['article_id'] == article_id]\n",
    "\n",
    "        # Ajouter la balise <dicotopo> à la balise article avec le code place_id\n",
    "        dicotopo_code = liage_row['place_id'].values[0]\n",
    "        dicotopo_elem = ET.Element('dicotopo')\n",
    "        dicotopo_elem.text = dicotopo_code\n",
    "        article.append(dicotopo_elem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e600ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrer le fichier XML modifié\n",
    "tree.write('../../utils/pouille/out/reinjection_out/po7_dicotopo.xml', encoding='UTF-8', xml_declaration=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
