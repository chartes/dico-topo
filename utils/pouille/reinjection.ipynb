{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a541d55",
   "metadata": {},
   "source": [
    "# Liage entre dicotopo et le pouillé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f337ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On importe nos dataframes nécessaires à la réinjection\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "#On importe les différents fichiers nécessaires. \n",
    "\n",
    "liage_po = pd.read_csv('../../utils/pouille/out/linking_out/liage_po7.csv', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ae152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne garde que les départements utiles à notre liage\n",
    "\n",
    "dpt_list = liage_po['dpt_code'].unique().tolist()\n",
    "dpt_list.remove(\"none\")\n",
    "dpt_list.sort()\n",
    "print(dpt_list)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a568ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# On définit le folder path\n",
    "main_folder = '../../data'\n",
    "\n",
    "#les fichiers avec les ID dicotopo sont tous appelés output7.xml.\n",
    "def is_valid_xml_filename(file_path):\n",
    "    if os.path.basename(file_path) == 'output7.xml':\n",
    "        try:\n",
    "            tree = ET.parse(file_path)\n",
    "            root = tree.getroot()\n",
    "            dep_attribute = root.attrib.get('dep')\n",
    "            if dep_attribute and dep_attribute.isdigit() and dep_attribute in dpt_list:\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    \n",
    "    return False\n",
    "\n",
    "# On crée une liste pour y mettre le data \n",
    "data = []\n",
    "\n",
    "# on cherche nos output7.xml\n",
    "for root_dir, _, files in os.walk(main_folder):\n",
    "    for filename in files:\n",
    "        file_path = os.path.join(root_dir, filename)\n",
    "        if is_valid_xml_filename(file_path):\n",
    "            try:\n",
    "                xml_tree = ET.parse(file_path)\n",
    "                root_element = xml_tree.getroot()\n",
    "            except ET.ParseError as e:\n",
    "                print(f\"Error parsing XML file {file_path}: {e}\")\n",
    "                continue  # Au cas où il y ait une erreur; pour que nous puissions voir\n",
    "\n",
    "            #on extrait le old-id (pour la provenance) et le id (pour l'identifiant)   \n",
    "            for article in root_element.findall('.//article'):\n",
    "                article_old_id = article.get('old-id')\n",
    "                article_id = article.get('id')\n",
    "                \n",
    "                # on extrait notre vedette\n",
    "                vedette = article.find('./vedette/sm').text if article.find('./vedette/sm') is not None else ''\n",
    "\n",
    "                # on extrait tout de notre définition en trois colonnes; typologie, insee et localisation\n",
    "                definition_typologie = ''\n",
    "                definition_localisation = ''\n",
    "                insee = ''\n",
    "                definition_elements = article.findall('./definition/*')\n",
    "                for element in definition_elements:\n",
    "                    if element.tag == 'typologie':\n",
    "                        definition_typologie = element.text\n",
    "                    elif element.tag == 'localisation':\n",
    "                        localisation_content = ET.tostring(element, encoding='unicode')\n",
    "                        localisation_match = re.search(r'<localisation>(.*?)<\\/localisation>', localisation_content)\n",
    "                        if localisation_match:\n",
    "                            definition_localisation = re.sub(r'<[^>]*>', '', localisation_match.group(1))\n",
    "                        insee_elem = element.find('./commune[@insee]')\n",
    "                        if insee_elem is not None:\n",
    "                            insee = insee_elem.get('insee')\n",
    "\n",
    "                data.append({\n",
    "                    'id': article_id,\n",
    "                    'old-id' : article_old_id,\n",
    "                    'vedette': vedette,\n",
    "                    'definition_typologie': definition_typologie,\n",
    "                    'definition_localisation': definition_localisation,\n",
    "                    'insee': insee\n",
    "                })\n",
    "\n",
    "# on crée un dataframe\n",
    "columns = ['id', 'old-id', 'vedette', 'definition_typologie', 'definition_localisation', 'insee']\n",
    "places = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "# on print\n",
    "print(places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726ca238",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On applique la fonction voulue par Olivier pour supprimer les accents etc\n",
    "\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "def replace_special_characters(text):\n",
    "    text = unidecode(text)\n",
    "    text = re.sub(r'[-\\'(),.]', ' ', text)  # Remlace également les parenthèses et les virgules\n",
    "    return text\n",
    "\n",
    "\n",
    "liage_po['vedette'] = liage_po['vedette'].astype(str)\n",
    "places['vedette'] = places['vedette'].astype(str)\n",
    "\n",
    "liage_po['vedette'] = liage_po['vedette'].apply(replace_special_characters)\n",
    "places['vedette'] = places['vedette'].apply(replace_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62601c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../../utils/pouille/resources/tokens_dicotopo.txt'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    tokens = file.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b9952d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_words(text, tokens):\n",
    "    text = replace_special_characters(text)  # Appliquer la fonction replace_special_characters\n",
    "    words = text.split()\n",
    "    words = [word for word in words if not re.search(r'\\b{}\\b'.format(re.escape(word.lower())), tokens)]\n",
    "    filtered_text = ' '.join(words).strip() \n",
    "    return filtered_text\n",
    "\n",
    "liage_po['vedette'] = liage_po['vedette'].apply(lambda x: filter_words(x, tokens=tokens))\n",
    "places['vedette'] = places['vedette'].apply(lambda x: filter_words(x, tokens=tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9814e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c89315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe à charger\n",
    "liages_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec86f048",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop_po = ['localisationde', 'dpt_code', 'canton_code', 'method', 'reference']\n",
    "\n",
    "# Renommer la colonne 'vedette' en 'label'\n",
    "places.rename(columns={'vedette': 'label'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4d8700c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des articles de type commune (ceux qui n’ont pas de commune de localisation)\n",
    "\n",
    "communes_df = liage_po[liage_po['localisationco'] == 'none']\n",
    "communes_df = communes_df.drop(columns=columns_to_drop_po)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b880f7",
   "metadata": {},
   "source": [
    "# Communes exact match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcaa012",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on lie par exact match vedette / label\n",
    "\n",
    "#on enlève les lignes sans insee_code de liage_po7: elles ne servent à rien\n",
    "communes_df_nonan = communes_df.dropna(subset=['insee_code'])\n",
    "\n",
    "liage_exact_communes = pd.merge(communes_df_nonan,\n",
    "                      places,\n",
    "                      how='inner',\n",
    "                      left_on=['insee_code','vedette'],\n",
    "                      right_on=['insee', 'label'])\n",
    "\n",
    "\n",
    "# Check for duplicate entries\n",
    "duplicates = liage_exact_communes.duplicated(['article_id'], keep=False)\n",
    "if duplicates.any():\n",
    "    liage_exact_communes = liage_exact_communes[~duplicates]\n",
    "    \n",
    "# Add a 'method' column with value 'dpt_exact'\n",
    "liage_exact_communes['method_dicotopo'] = 'communes_exact'\n",
    "\n",
    "\n",
    "# Update the linked_places_df dataframe\n",
    "liages_df = pd.concat([liages_df, liage_exact_communes]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf258d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "liages_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b5fd6",
   "metadata": {},
   "source": [
    "# Lieux dans des communes exact match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6022fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraction des articles appartenant à une commune (ceux ont une commune de localisation)\n",
    "\n",
    "localisationco_df = liage_po[liage_po['localisationco'] != 'none']\n",
    "localisationco_df = localisationco_df.drop(columns=columns_to_drop_po)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be773dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on lie par exact match vedette de la localisationco / label\n",
    "\n",
    "#on enlève les lignes sans insee_code de liage_po7: elles ne servent à rien\n",
    "localisationco_df_nonan = localisationco_df.dropna(subset=['insee_code'])\n",
    "\n",
    "liage_exact_localisationco = pd.merge(localisationco_df_nonan,\n",
    "                      places,\n",
    "                      how='inner',\n",
    "                      left_on=['insee_code','vedette'],\n",
    "                      right_on=['insee', 'label'])\n",
    "\n",
    "\n",
    "# Check for duplicate entries\n",
    "duplicates = liage_exact_localisationco.duplicated(['article_id'], keep=False)\n",
    "if duplicates.any():\n",
    "    liage_exact_localisationco = liage_exact_localisationco[~duplicates]\n",
    "    \n",
    "# Add a 'method' column with value 'dpt_exact'\n",
    "liage_exact_localisationco['method_dicotopo'] = 'localisationco_exact'\n",
    "\n",
    "\n",
    "# Update the linked_places_df dataframe\n",
    "liages_df = pd.concat([liages_df, liage_exact_localisationco]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a5a4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "liages_df.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2a3f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "liages_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d9e910",
   "metadata": {},
   "source": [
    "# Fuzzy match communes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0c96c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from thefuzz import fuzz\n",
    "\n",
    "communes_df_nonan = communes_df_nonan[~communes_df_nonan.article_id.isin(liages_df['article_id'])]\n",
    "\n",
    "liage_fuzzy_communes = pd.merge(communes_df_nonan,\n",
    "                                places,\n",
    "                                how='inner',\n",
    "                                left_on=['insee_code'],\n",
    "                                right_on=['insee'])\n",
    "\n",
    "# Define a threshold for similarity (50%: tout ce qui est plus bas donne des résultats vraiment trop erronnés.)\n",
    "similarity_threshold = 50\n",
    "\n",
    "# Filter communes based on fuzzy matching with insee_code\n",
    "def fuzzy_match(row):\n",
    "    vedette = row['vedette']\n",
    "    label = row['label']\n",
    "\n",
    "    if isinstance(vedette, str) and not pd.isnull(vedette) and isinstance(label, str) and not pd.isnull(label):\n",
    "        # Calculate the fuzzy similarity score\n",
    "        similarity_score = fuzz.ratio(vedette, label)\n",
    "        if similarity_score >= similarity_threshold:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "liage_fuzzy_communes = liage_fuzzy_communes[liage_fuzzy_communes.apply(fuzzy_match, axis=1)]\n",
    "\n",
    "# Add a 'method' column with value 'dicotopo_fuzzy'\n",
    "liage_fuzzy_communes['method_dicotopo'] = 'communes_fuzzy'\n",
    "\n",
    "# Update the linked_places_df dataframe\n",
    "liages_df = pd.concat([liages_df, liage_fuzzy_communes]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a67d4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "liage_fuzzy_communes.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcaf99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "liage_fuzzy_communes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44bab95",
   "metadata": {},
   "source": [
    "# Fuzzy match localisationco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05daa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "localisationco_df_nonan = localisationco_df_nonan[~localisationco_df_nonan.article_id.isin(liages_df['article_id'])]\n",
    "\n",
    "liage_fuzzy_localisationco = pd.merge(localisationco_df_nonan,\n",
    "                                places,\n",
    "                                how='inner',\n",
    "                                left_on=['insee_code'],\n",
    "                                right_on=['insee'])\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from thefuzz import fuzz\n",
    "\n",
    "# Define a threshold for similarity (50%)\n",
    "similarity_threshold = 50\n",
    "\n",
    "# Filter localisationco_df based on fuzzy matching with insee_code\n",
    "def fuzzy_match(row):\n",
    "    vedette = row['vedette']\n",
    "    label = row['label']\n",
    "\n",
    "    if isinstance(vedette, str) and not pd.isnull(vedette) and isinstance(label, str) and not pd.isnull(label):\n",
    "        # Calculate the fuzzy similarity score\n",
    "        similarity_score = fuzz.ratio(vedette, label)\n",
    "        if similarity_score >= similarity_threshold:\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "# Assuming you have defined liage_fuzzy_localisationco earlier\n",
    "liage_fuzzy_localisationco = liage_fuzzy_localisationco[liage_fuzzy_localisationco.apply(fuzzy_match, axis=1)]\n",
    "\n",
    "# Add a 'method' column with value 'dicotopo_fuzzy'\n",
    "liage_fuzzy_localisationco['method_dicotopo'] = 'localisationco_fuzzy'\n",
    "\n",
    "# Update the linked_places_df dataframe\n",
    "liages_df = pd.concat([liages_df, liage_fuzzy_localisationco]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e7333c",
   "metadata": {},
   "outputs": [],
   "source": [
    "liage_fuzzy_localisationco.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0ae569",
   "metadata": {},
   "source": [
    "# Exportation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf80647",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on append les deux dataframes ensemble\n",
    "\n",
    "new_rows_df = liage_po[~liage_po['article_id'].isin(liages_df['article_id'])]\n",
    "\n",
    "if 'method_dicotopo' not in new_rows_df.columns:\n",
    "    new_rows_df['method_dicotopo'] = 'nulle'\n",
    "\n",
    "liages_df = liages_df.append(new_rows_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6904cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "liages_df.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d46d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#on ajoute les lignes de notre pouillé qui n'ont pas eu de match avec dicotopo pour vérification manuelle\n",
    "\n",
    "remaining_rows = liage_po[~liage_po['article_id'].isin(liages_df['article_id'])]\n",
    "updated_liages_df = pd.concat([liages_df, remaining_rows], ignore_index=True)\n",
    "\n",
    "#on sort par article_id pour plus de clarté\n",
    "updated_liages_df = updated_liages_df.sort_values('article_id')\n",
    "updated_liages_df = updated_liages_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645695f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_liages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b5cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_liages_df.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48745548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sauvegarder le dataframe fusionné\n",
    "updated_liages_df.to_csv('../../utils/pouille/out/reinjection_out/po7_dicotopo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c61861",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcae589",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992d1e1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781b7d64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94ebb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#partie pour plus tard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c6b550",
   "metadata": {},
   "source": [
    "# Réinsertion dans le fichier XML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211e1cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Charger le fichier XML\n",
    "tree = ET.parse('../../utils/pouille/out/linking_out/PO_t7_modified.xml')\n",
    "root = tree.getroot()\n",
    "# Replace nan values with empty string in the DataFrame (juste pour le temps où olivier corrige)\n",
    "liages_df = liages_df.replace({np.nan: \"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3de8abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pour chaque article dans le XML\n",
    "for article in root.findall('article'):\n",
    "    # Récupérer l'article_id\n",
    "    article_id = article.get('old-id')\n",
    "\n",
    "    # Vérifier si l'article_id est présent dans le DataFrame\n",
    "    if article_id in liages_df['article_id'].values:\n",
    "        # Récupérer la ligne correspondante dans le DataFrame\n",
    "        liage_row = liages_df.loc[liages_df['article_id'] == article_id]\n",
    "\n",
    "        # Récupérer la valeur de place_id\n",
    "        dicotopo_code = liage_row['id'].values[0]\n",
    "\n",
    "        # Ajouter l'attribut 'dicotopo' à la balise article\n",
    "        article.set('dicotopo', dicotopo_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e600ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enregistrer le fichier XML modifié\n",
    "tree.write('../../utils/pouille/out/reinjection_out/po7_dicotopo.xml', encoding='UTF-8', xml_declaration=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
