{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cac7386",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:52:04.044526Z",
     "start_time": "2023-04-24T15:52:03.497398Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18eee16",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "\n",
    "1. extration des articles à lier et des features utiles dans df\n",
    "2. chargement du référentiel des communes (COG 2011) dans le df main_insee_commune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a048358",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:52:09.047192Z",
     "start_time": "2023-04-24T15:52:08.565647Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extraction des features de chaque article à lier dans un df\n",
    "\n",
    "xml_file = '../../data/PO_t11/PO_t11.xml'\n",
    "xml_tree = etree.parse(xml_file)\n",
    "\n",
    "data = []\n",
    "\n",
    "i = 0 # compter les articles\n",
    "\n",
    "for article in xml_tree.xpath('//article'):\n",
    "    i+=1\n",
    "    # on ne retient pas les lieux hors France\n",
    "    if article.find('./localisationpa') is not None:\n",
    "        continue\n",
    "    vedettes = article.xpath('./vedette/i')\n",
    "    # on ne retient que la première vedette\n",
    "    vedette = vedettes[0].text if vedettes else ''\n",
    "\n",
    "    # on ne retient que le premier dpt de localisation\n",
    "    localisationde = article.find('./localisationde')\n",
    "    localisationde = localisationde.text if localisationde is not None else 'none'\n",
    "\n",
    "    # on ne retient que le premier canton de localisation\n",
    "    localisationca = article.find('./localisationca')\n",
    "    if localisationca is not None:\n",
    "        localisationca = re.search(\n",
    "            r'<localisationca>(.*?)<\\/localisationca>',\n",
    "            etree.tostring(localisationca, encoding=str)\n",
    "        ).group(1)\n",
    "        '''\n",
    "        cases:\n",
    "        - 'c<sup>on</sup> de '\n",
    "        - 'c<sup>on</sup> du '\n",
    "        - 'c<sup>on</sup> d’'\n",
    "        - 'c<sup>on</sup> de la '\n",
    "        - 'c<sup>on</sup> de l’'\n",
    "        - 'c<sup>on</sup> des '\n",
    "        '''\n",
    "        localisationca = re.sub(r\"c<sup>on</sup> (de |d’|de la |du |de l’|des )\", '', localisationca)\n",
    "    else:\n",
    "        localisationca = 'none'\n",
    "\n",
    "    #  on ne retient que la première commune de localisation\n",
    "    localisationco = article.find('./localisationco')\n",
    "    if localisationco is not None:\n",
    "        localisationco = re.search(\n",
    "            r'<localisationco>(.*?)<\\/localisationco>',\n",
    "            etree.tostring(localisationco, encoding=str)\n",
    "        ).group(1)\n",
    "        '''\n",
    "        cases:\n",
    "        - 'c<sup>on</sup> de '\n",
    "        - 'c<sup>on</sup> du '\n",
    "        - 'c<sup>on</sup> d’'\n",
    "        - 'c<sup>on</sup> de la '\n",
    "        - 'c<sup>on</sup> de l’'\n",
    "        - 'c<sup>on</sup> des '\n",
    "        - 'c<sup>nes</sup> de '\n",
    "        - 'c<sup>nes</sup> d’'\n",
    "            '''\n",
    "        localisationco = re.sub(r\"c<sup>ne(s)?</sup> (de |d’|de la |du |de l’|des )\", '', localisationco)\n",
    "\n",
    "    else:\n",
    "        localisationco = 'none'\n",
    "\n",
    "    # Extraire le contenu textuel de la balise \"article\"\n",
    "    article_text = re.sub(r'\\W', ' ', article.xpath('string(.)'))\n",
    "\n",
    "    # on insère tout dans un dictionnaire\n",
    "    data.append({\n",
    "        'old-id': article.get('old-id'),\n",
    "        'vedette': vedette,\n",
    "        'localisationde': localisationde,\n",
    "        'localisationca': localisationca,\n",
    "        'localisationco': localisationco,\n",
    "        'reference': article_text  # Ajouter la colonne \"reference\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "'''\n",
    "article : nombre d’articles dans la source => `//article`\n",
    "article_to_link : nombre d’articles à lier (en France) => `//article[not(localisationpa)]`\n",
    "article_commune : nombre d’articles de type commune => `//article[not(localisationpa) and not(localisationco)]`\n",
    "article_loc_com : nombre d’articles localisés dans une commune => `//article[not(localisationpa) and localisationco]`\n",
    "'''\n",
    "report = dict(\n",
    "    article = i,\n",
    "    article_to_link = len(df.index),\n",
    "    article_commune = (df.localisationco == 'none').sum(),\n",
    "    article_loc_com = (df.localisationco != 'none').sum()\n",
    ")\n",
    "\n",
    "# check\n",
    "[print(k,':',v) for k, v in report.items()]\n",
    "df.iloc[1500:1510, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de27a1a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copiez les colonnes d'origine\n",
    "df['vedette_orig'] = df['vedette']\n",
    "df['localisationco_orig'] = df['localisationco']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d49ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#premier préprocessing pour les caractères spéciaux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e67c33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def replace_special_characters(text):\n",
    "    text = unidecode(text)\n",
    "    text = re.sub(r'[-\\'\\[\\]\\(\\)]', ' ', text)\n",
    "    return text\n",
    "\n",
    "\n",
    "df['vedette'] = df['vedette'].apply(replace_special_characters)\n",
    "df['localisationco'] = df['localisationco'].apply(replace_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30148788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f5e60e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:52:12.071062Z",
     "start_time": "2023-04-24T15:52:12.022183Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ajout du dpt code au df\n",
    "dpt_df = pd.read_csv('../../utils/pouille/resources/departements-region.csv')\n",
    "dpt_dict = dict(zip(dpt_df['dep_name'], dpt_df['num_dep']))\n",
    "\n",
    "# on ajoute notre colonne avec les numéros des départements qui matchent\n",
    "df['dpt_code'] = df['localisationde'].apply(lambda x: dpt_dict.get(x, 'none'))\n",
    "\n",
    "#on renomme et réordonne pour plus de clarté.\n",
    "df = df.rename(columns={'old-id' : 'article_id', 'localisationca' : 'canton_code', 'localisationco_present' : 'nom_commune'})\n",
    "df = df[['article_id', 'vedette', 'localisationde', 'dpt_code', 'canton_code', 'localisationco', 'reference', 'vedette_orig', 'localisationco_orig']]\n",
    "\n",
    "df.iloc[1500:1510, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99c00fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:52:30.119282Z",
     "start_time": "2023-04-24T15:52:29.938727Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Chargement du référentiel des communes\n",
    "fields = ['insee_code', 'DEP_id', 'NCCENR']\n",
    "main_insee_commune = pd.read_csv(\"../../utils/pouille/resources/main_insee_commune.tsv\",\n",
    "                                 delimiter='\\t',\n",
    "                                 usecols=fields,\n",
    "                                 dtype={'insee_code': 'string'})\n",
    "main_insee_commune['DEP_id'] = main_insee_commune['DEP_id'].apply(lambda x: x[4:])\n",
    "main_insee_commune.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e14a2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_insee_commune['NCCENR_orig'] = main_insee_commune['NCCENR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698c5278",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_insee_commune['NCCENR'] = main_insee_commune['NCCENR'].apply(replace_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690aac6c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_insee_commune.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6250e6f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:52:36.360982Z",
     "start_time": "2023-04-24T15:52:36.338280Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Liste les départements présents pour mieux filtrer quand pas de localisationde\n",
    "dpt_list = df['dpt_code'].unique().tolist()\n",
    "dpt_list.remove(\"none\")\n",
    "dpt_list.sort()\n",
    "print(dpt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5f3c2b-f2df-4ec9-9d43-e6166bb238a2",
   "metadata": {},
   "source": [
    "# Exact match methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1066fb5e",
   "metadata": {},
   "source": [
    "## Liage des articles de type commune (exact match mathod 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13592132",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:52:41.335036Z",
     "start_time": "2023-04-24T15:52:41.323521Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataframe à charger\n",
    "linked_places_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175b7996",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:52:46.553012Z",
     "start_time": "2023-04-24T15:52:46.488439Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extraction des articles de type commune (ceux qui n’ont pas de commune de localisation)\n",
    "\n",
    "communes_df = df[df['localisationco'] == 'none']\n",
    "communes_df.iloc[500:1000, :]\n",
    "#communes_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09178046-8b4c-485c-abb5-4084f5ee1402",
   "metadata": {},
   "source": [
    "### With dpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51241f0a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:52:55.339073Z",
     "start_time": "2023-04-24T15:52:55.297659Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge communes_df and main_insee_commune on vedette and dpt_code\n",
    "communes_exact_dpt_df = pd.merge(communes_df,\n",
    "                                 main_insee_commune,\n",
    "                                 how='inner',\n",
    "                                 left_on=['vedette', 'dpt_code'],\n",
    "                                 right_on=['NCCENR', 'DEP_id'])\n",
    "\n",
    "# Create a new column 'insee' by combining NCCENR and insee_code\n",
    "communes_exact_dpt_df['insee'] = communes_exact_dpt_df.apply(lambda row: f\"{row['NCCENR']} ({row['insee_code']})\", axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "communes_exact_dpt_df = communes_exact_dpt_df.drop(columns=['DEP_id', 'NCCENR', 'insee_code'], axis=1)\n",
    "communes_exact_dpt_df = communes_exact_dpt_df.rename(columns={'insee': 'insee_code'})\n",
    "\n",
    "# Add a 'method' column with value 'dpt_exact'\n",
    "communes_exact_dpt_df['method'] = 'dpt_exact'\n",
    "\n",
    "# Check for duplicate entries\n",
    "duplicates = communes_exact_dpt_df.duplicated(['article_id'], keep=False)\n",
    "if duplicates.any():\n",
    "    communes_exact_dpt_df = communes_exact_dpt_df[~duplicates]\n",
    "\n",
    "\n",
    "# Update the linked_places_df dataframe\n",
    "linked_places_df = pd.concat([linked_places_df, communes_exact_dpt_df]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac43df1-ced3-491b-b342-c8a928beef7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:52:58.255956Z",
     "start_time": "2023-04-24T15:52:58.241911Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tests\n",
    "#communes_exact_dpt_df.head(5)\n",
    "communes_exact_dpt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026b613d-565e-4a08-8648-2765638cae39",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:53:00.989327Z",
     "start_time": "2023-04-24T15:53:00.931756Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# des doublons de liage exact match dans un même dpt ?\n",
    "#communes_exact_dpt_df.article_id.duplicated().sum()\n",
    "communes_exact_dpt_df.loc[communes_exact_dpt_df.duplicated(keep=False, subset=['article_id']), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78081c25-ff84-480d-bef6-8ad3432bd37e",
   "metadata": {},
   "source": [
    "### Without dpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0601c9ea-cab9-48e1-8cf8-0ff839c9f2d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:53:07.843912Z",
     "start_time": "2023-04-24T15:53:07.802742Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge communes_df and main_insee_commune on vedette and NCCENR\n",
    "communes_exact_nodpt_df = pd.merge(communes_df.loc[communes_df['dpt_code'] == 'none'],\n",
    "                                   main_insee_commune[main_insee_commune.DEP_id.isin(dpt_list)],\n",
    "                                   how='inner',\n",
    "                                   left_on='vedette',\n",
    "                                   right_on='NCCENR')\n",
    "\n",
    "# Create a new column 'insee' by combining NCCENR and insee_code\n",
    "communes_exact_nodpt_df['insee'] = communes_exact_nodpt_df.apply(lambda row: f\"{row['NCCENR']} ({row['insee_code']})\", axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "communes_exact_nodpt_df = communes_exact_nodpt_df.drop(columns=['DEP_id', 'NCCENR', 'insee_code'], axis=1)\n",
    "communes_exact_nodpt_df = communes_exact_nodpt_df.rename(columns={'insee': 'insee_code'})\n",
    "\n",
    "# Add a 'method' column with value 'nodpt_exact'\n",
    "communes_exact_nodpt_df['method'] = 'nodpt_exact'\n",
    "\n",
    "duplicates = communes_exact_nodpt_df.duplicated(['article_id'], keep=False)\n",
    "if duplicates.any():\n",
    "    communes_exact_nodpt_df = communes_exact_nodpt_df[~duplicates]\n",
    "\n",
    "# Update the linked_places_df dataframe\n",
    "linked_places_df = pd.concat([linked_places_df, communes_exact_nodpt_df]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7f9dd1-6dc7-48a2-8f5b-360c485d106e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:53:14.414603Z",
     "start_time": "2023-04-24T15:53:14.371744Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# On cherche à savoir combien ont été liés sans information de département ; cela signifie que dans le XML,\n",
    "# on a des communes qui ne sont pas localisées.\n",
    "# Test\n",
    "communes_exact_nodpt_df\n",
    "#linked_places_df.shape\n",
    "communes_exact_nodpt_df.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3236547-78d1-46d5-9279-efd31ab0061b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:54:04.059727Z",
     "start_time": "2023-04-24T15:54:04.024714Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: on teste quoi ?\n",
    "communes_exact_nodpt_df.loc[communes_exact_nodpt_df.duplicated(keep=False,subset=['article_id']), :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14329046-67dc-49ab-bbd6-e8eefea12bac",
   "metadata": {},
   "source": [
    "## Liage des communes de localisation (exact match method 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8349ce4a-59b9-42f3-900e-0cadb2008933",
   "metadata": {},
   "source": [
    "### With dpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1469cbc4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:56:41.888988Z",
     "start_time": "2023-04-24T15:56:41.842456Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extraction des articles appartenant à une commune (ceux ont une commune de localisation)\n",
    "\n",
    "pas_communes_df = df[df['localisationco'] != 'none']\n",
    "pas_communes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a1e95f-4aa6-4bee-b734-6a50be671a2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:56:54.574933Z",
     "start_time": "2023-04-24T15:56:54.552333Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge pas_communes_df and main_insee_commune on localisationco and dpt_code\n",
    "pas_communes_exact_dpt_df = pd.merge(pas_communes_df,\n",
    "                                     main_insee_commune,\n",
    "                                     how='inner',\n",
    "                                     left_on=['localisationco', 'dpt_code'],\n",
    "                                     right_on=['NCCENR', 'DEP_id'])\n",
    "\n",
    "# Create a new column 'insee' by combining NCCENR and insee_code\n",
    "pas_communes_exact_dpt_df['insee'] = pas_communes_exact_dpt_df.apply(lambda row: f\"{row['NCCENR']} ({row['insee_code']})\", axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "pas_communes_exact_dpt_df = pas_communes_exact_dpt_df.drop(columns=['DEP_id', 'NCCENR', 'insee_code'], axis=1)\n",
    "pas_communes_exact_dpt_df = pas_communes_exact_dpt_df.rename(columns={'insee': 'insee_code'})\n",
    "\n",
    "# Add a 'method' column with value 'dpt_exact'\n",
    "pas_communes_exact_dpt_df['method'] = 'dpt_exact'\n",
    "\n",
    "duplicates = pas_communes_exact_dpt_df.duplicated(['article_id'], keep=False)\n",
    "if duplicates.any():\n",
    "    pas_communes_exact_dpt_df = pas_communes_exact_dpt_df[~duplicates]\n",
    "\n",
    "# Update the linked_places_df dataframe\n",
    "linked_places_df = pd.concat([linked_places_df, pas_communes_exact_dpt_df]).drop_duplicates()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a0e7f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:57:34.021070Z",
     "start_time": "2023-04-24T15:57:33.990382Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tests\n",
    "pas_communes_exact_dpt_df.head(5)\n",
    "#pas_communes_exact_dpt_df.shape\n",
    "pas_communes_exact_dpt_df.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63a52910-0e21-4765-90ac-b6bd340f7e06",
   "metadata": {},
   "source": [
    "### Without dpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e117e13-8888-4b86-ba79-5d135c52501d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:57:54.840107Z",
     "start_time": "2023-04-24T15:57:54.800277Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge pas_communes_df and main_insee_commune on localisationco and NCCENR\n",
    "pas_communes_exact_nodpt_df = pd.merge(pas_communes_df.loc[pas_communes_df['dpt_code'] == 'none'],\n",
    "                                       main_insee_commune[main_insee_commune.DEP_id.isin(dpt_list)],\n",
    "                                       how='inner',\n",
    "                                       left_on='localisationco',\n",
    "                                       right_on='NCCENR')\n",
    "\n",
    "# Create a new column 'insee' by combining NCCENR and insee_code\n",
    "pas_communes_exact_nodpt_df['insee'] = pas_communes_exact_nodpt_df.apply(lambda row: f\"{row['NCCENR']} ({row['insee_code']})\", axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "pas_communes_exact_nodpt_df = pas_communes_exact_nodpt_df.drop(columns=['DEP_id', 'NCCENR', 'insee_code'], axis=1)\n",
    "pas_communes_exact_nodpt_df = pas_communes_exact_nodpt_df.rename(columns={'insee': 'insee_code'})\n",
    "\n",
    "# Add a 'method' column with value 'nodpt_exact'\n",
    "pas_communes_exact_nodpt_df['method'] = 'nodpt_exact'\n",
    "\n",
    "duplicates = pas_communes_exact_nodpt_df.duplicated(['article_id'], keep=False)\n",
    "if duplicates.any():\n",
    "    pas_communes_exact_nodpt_df = pas_communes_exact_nodpt_df[~duplicates]\n",
    "\n",
    "# Update the linked_places_df dataframe\n",
    "linked_places_df = pd.concat([linked_places_df, pas_communes_exact_nodpt_df]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f7ae81",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:58:06.096448Z",
     "start_time": "2023-04-24T15:58:06.081292Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# On cherche à savoir combien ont été liés sans information de département ; cela signifie que dans le XML,\n",
    "# on a des lieux dans des communes qui ne sont pas localisés.\n",
    "# Test\n",
    "pas_communes_exact_nodpt_df\n",
    "#linked_places_df.shape\n",
    "pas_communes_exact_nodpt_df.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ab58012",
   "metadata": {},
   "source": [
    "## Liage des articles de type commune (exact match method 2)\n",
    "\n",
    "On cherche à ré-effectuer un deuxième liage en exact match pour tous les articles n'ayant pas été liés dans la première passe. Nous effectuons un pré-processing plus poussé ; on retire tous les mots d'une liste pré-définie par Olivier (tels que Le, La, L', ruisseau, bois, rivière, etc) sur les vedettes du pouillés + les NCCENR du référentiel INSEE puis on ré-applique notre script."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336e412-e3ba-4ab3-83a2-2662533b2581",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ac040c-8386-465b-9749-0ef6afe4ce47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = '../../utils/pouille/resources/tokens_dicotopo.txt'\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    tokens = file.read() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cc34ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# filtrer les mots des noms de lieux\n",
    "def filter_words(text, tokens):\n",
    "    text = replace_special_characters(text)  # Appliquer la fonction replace_special_characters\n",
    "    words = text.split()\n",
    "    words = [word for word in words if not re.search(r'\\b{}\\b'.format(re.escape(word.lower())), tokens)]\n",
    "    filtered_text = ' '.join(words).strip() \n",
    "    return filtered_text\n",
    "\n",
    "df['vedette'] = df['vedette'].apply(lambda x: filter_words(x, tokens=tokens))\n",
    "df['localisationco'] = df['localisationco'].apply(lambda x: filter_words(x, tokens=tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843ff352",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "main_insee_commune['NCCENR'] = main_insee_commune['NCCENR'].apply(lambda x: filter_words(x, tokens=tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280c71b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extraction des articles de type commune (ceux qui n’ont pas de commune de localisation)\n",
    "\n",
    "communes_df = df[df['localisationco'] == 'none']\n",
    "#communes_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c037024d",
   "metadata": {},
   "source": [
    "### with dpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82407255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge communes_df and main_insee_commune on vedette and dpt_code\n",
    "communes_exact_simple_dpt_df = pd.merge(communes_df,\n",
    "                                 main_insee_commune,\n",
    "                                 how='inner',\n",
    "                                 left_on=['vedette', 'dpt_code'],\n",
    "                                 right_on=['NCCENR', 'DEP_id'])\n",
    "\n",
    "# Create a new column 'insee' by combining NCCENR and insee_code\n",
    "communes_exact_simple_dpt_df['insee'] = communes_exact_simple_dpt_df.apply(lambda row: f\"{row['NCCENR']} ({row['insee_code']})\", axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "communes_exact_simple_dpt_df = communes_exact_simple_dpt_df.drop(columns=['DEP_id', 'NCCENR', 'insee_code'], axis=1)\n",
    "communes_exact_simple_dpt_df = communes_exact_simple_dpt_df.rename(columns={'insee': 'insee_code'})\n",
    "\n",
    "# Add a 'method' column with value 'dpt_exact'\n",
    "communes_exact_simple_dpt_df['method'] = 'dpt_exact_simple'\n",
    "\n",
    "duplicates = communes_exact_simple_dpt_df.duplicated(['article_id'], keep=False)\n",
    "if duplicates.any():\n",
    "    communes_exact_simple_dpt_df = communes_exact_simple_dpt_df[~duplicates]\n",
    "\n",
    "# Filtrer les lignes de communes_exact_simple_dpt_df avec la méthode \"dpt_exact_simple\"\n",
    "filtered_df = communes_exact_simple_dpt_df.loc[communes_exact_simple_dpt_df['method'] == 'dpt_exact_simple']\n",
    "\n",
    "# Filtrer les article_id qui ne sont pas déjà présents dans linked_places_df\n",
    "filtered_df = filtered_df[~filtered_df['article_id'].isin(linked_places_df['article_id'])]\n",
    "\n",
    "# Ajouter les lignes filtrées à linked_places_df\n",
    "linked_places_df = pd.concat([linked_places_df, filtered_df]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88da89f",
   "metadata": {},
   "source": [
    "### without dpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04be71ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge communes_df and main_insee_commune on vedette and NCCENR\n",
    "communes_exact_simple_nodpt_df = pd.merge(communes_df.loc[communes_df['dpt_code'] == 'none'],\n",
    "                                   main_insee_commune[main_insee_commune.DEP_id.isin(dpt_list)],\n",
    "                                   how='inner',\n",
    "                                   left_on='vedette',\n",
    "                                   right_on='NCCENR')\n",
    "\n",
    "# Create a new column 'insee' by combining NCCENR and insee_code\n",
    "communes_exact_simple_nodpt_df['insee'] = communes_exact_simple_nodpt_df.apply(lambda row: f\"{row['NCCENR']} ({row['insee_code']})\", axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "communes_exact_simple_nodpt_df = communes_exact_simple_nodpt_df.drop(columns=['DEP_id', 'NCCENR', 'insee_code'], axis=1)\n",
    "communes_exact_simple_nodpt_df = communes_exact_simple_nodpt_df.rename(columns={'insee': 'insee_code'})\n",
    "\n",
    "# Add a 'method' column with value 'nodpt_exact'\n",
    "communes_exact_simple_nodpt_df['method'] = 'nodpt_exact_simple'\n",
    "\n",
    "duplicates = communes_exact_simple_nodpt_df.duplicated(['article_id'], keep=False)\n",
    "if duplicates.any():\n",
    "    communes_exact_simple_nodpt_df = communes_exact_simple_nodpt_df[~duplicates]\n",
    "\n",
    "# Filtrer les lignes de communes_exact_simple_dpt_df avec la méthode \"dpt_exact_simple\"\n",
    "filtered_df = communes_exact_simple_nodpt_df.loc[communes_exact_simple_nodpt_df['method'] == 'nodpt_exact_simple']\n",
    "\n",
    "# Filtrer les article_id qui ne sont pas déjà présents dans linked_places_df\n",
    "filtered_df = filtered_df[~filtered_df['article_id'].isin(linked_places_df['article_id'])]\n",
    "\n",
    "# Ajouter les lignes filtrées à linked_places_df\n",
    "linked_places_df = pd.concat([linked_places_df, filtered_df]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cb8feb",
   "metadata": {},
   "source": [
    "## Liage des communes de localisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc447870",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extraction des articles appartenant à une commune (ceux ont une commune de localisation)\n",
    "\n",
    "pas_communes_df = df[df['localisationco'] != 'none']\n",
    "pas_communes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d34a81",
   "metadata": {},
   "source": [
    "### with dpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306835d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Merge pas_communes_df and main_insee_commune on localisationco and dpt_code\n",
    "pas_communes_exact_simple_dpt_df = pd.merge(pas_communes_df,\n",
    "                                     main_insee_commune,\n",
    "                                     how='inner',\n",
    "                                     left_on=['localisationco', 'dpt_code'],\n",
    "                                     right_on=['NCCENR', 'DEP_id'])\n",
    "\n",
    "# Create a new column 'insee' by combining NCCENR and insee_code\n",
    "pas_communes_exact_simple_dpt_df['insee'] = pas_communes_exact_simple_dpt_df.apply(lambda row: f\"{row['NCCENR']} ({row['insee_code']})\", axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "pas_communes_exact_simple_dpt_df = pas_communes_exact_simple_dpt_df.drop(columns=['DEP_id', 'NCCENR', 'insee_code'], axis=1)\n",
    "pas_communes_exact_simple_dpt_df = pas_communes_exact_simple_dpt_df.rename(columns={'insee': 'insee_code'})\n",
    "\n",
    "# Add a 'method' column with value 'dpt_exact'\n",
    "pas_communes_exact_simple_dpt_df['method'] = 'dpt_exact_simple'\n",
    "\n",
    "duplicates = pas_communes_exact_simple_dpt_df.duplicated(['article_id'], keep=False)\n",
    "if duplicates.any():\n",
    "    pas_communes_exact_simple_dpt_df = pas_communes_exact_simple_dpt_df[~duplicates]\n",
    "\n",
    "# Filtrer les lignes de communes_exact_simple_dpt_df avec la méthode \"dpt_exact_simple\"\n",
    "filtered_df = pas_communes_exact_simple_dpt_df.loc[pas_communes_exact_simple_dpt_df['method'] == 'dpt_exact_simple']\n",
    "\n",
    "# Filtrer les article_id qui ne sont pas déjà présents dans linked_places_df\n",
    "filtered_df = filtered_df[~filtered_df['article_id'].isin(linked_places_df['article_id'])]\n",
    "\n",
    "# Ajouter les lignes filtrées à linked_places_df\n",
    "linked_places_df = pd.concat([linked_places_df, filtered_df]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b50ba3",
   "metadata": {},
   "source": [
    "### without dpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fabf9be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Merge pas_communes_df and main_insee_commune on localisationco and NCCENR\n",
    "pas_communes_exact_simple_nodpt_df = pd.merge(pas_communes_df.loc[pas_communes_df['dpt_code'] == 'none'],\n",
    "                                       main_insee_commune[main_insee_commune.DEP_id.isin(dpt_list)],\n",
    "                                       how='inner',\n",
    "                                       left_on='localisationco',\n",
    "                                       right_on='NCCENR')\n",
    "\n",
    "# Create a new column 'insee' by combining NCCENR and insee_code\n",
    "pas_communes_exact_simple_nodpt_df['insee'] = pas_communes_exact_simple_nodpt_df.apply(lambda row: f\"{row['NCCENR']} ({row['insee_code']})\", axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "pas_communes_exact_simple_nodpt_df = pas_communes_exact_simple_nodpt_df.drop(columns=['DEP_id', 'NCCENR', 'insee_code'], axis=1)\n",
    "pas_communes_exact_simple_nodpt_df = pas_communes_exact_simple_nodpt_df.rename(columns={'insee': 'insee_code'})\n",
    "\n",
    "# Add a 'method' column with value 'nodpt_exact'\n",
    "pas_communes_exact_simple_nodpt_df['method'] = 'nodpt_exact_simple'\n",
    "\n",
    "duplicates = pas_communes_exact_simple_nodpt_df.duplicated(['article_id'], keep=False)\n",
    "if duplicates.any():\n",
    "    pas_communes_exact_simple_nodpt_df = pas_communes_exact_simple_nodpt_df[~duplicates]\n",
    "\n",
    "# Filtrer les lignes de communes_exact_simple_dpt_df avec la méthode \"dpt_exact_simple\"\n",
    "filtered_df = pas_communes_exact_simple_nodpt_df.loc[pas_communes_exact_simple_nodpt_df['method'] == 'nodpt_exact_simple']\n",
    "\n",
    "# Filtrer les article_id qui ne sont pas déjà présents dans linked_places_df\n",
    "filtered_df = filtered_df[~filtered_df['article_id'].isin(linked_places_df['article_id'])]\n",
    "\n",
    "# Ajouter les lignes filtrées à linked_places_df\n",
    "linked_places_df = pd.concat([linked_places_df, filtered_df]).drop_duplicates()\n",
    "\n",
    "linked_places_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c61beb-454d-4618-832b-3a249f771d76",
   "metadata": {},
   "source": [
    "# Fuzzy match method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06689bac-6c71-4062-a05b-2e4ed4897a76",
   "metadata": {},
   "source": [
    "## Liage des articles de type commune (fuzzy method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44763aaa-ba33-45d8-ade2-a824ebcd75fe",
   "metadata": {},
   "source": [
    "### With dpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1cc921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importer la fonction \"fuzz\" du module \"thefuzz\"\n",
    "from thefuzz import fuzz\n",
    "\n",
    "# Créer un dictionnaire de correspondance entre les NCCENR et les codes INSEE\n",
    "# À partir du DataFrame \"main_insee_commune\", utiliser la colonne 'NCCENR' comme index et la colonne 'insee_code' comme valeurs pour créer le dictionnaire.\n",
    "nccenr_to_insee = main_insee_commune.set_index('NCCENR')['insee_code'].to_dict()\n",
    "\n",
    "# Filtrer les communes à lier avec le département de localisation en utilisant des correspondances floues (fuzzy match)\n",
    "# Sélectionner les lignes du DataFrame \"communes_df\" qui ne sont pas présentes dans la colonne 'article_id' du DataFrame \"linked_places_df\"\n",
    "# et dont la valeur de la colonne 'dpt_code' n'est pas égale à 'none'.\n",
    "communes_fuzzy_dpt_df = communes_df[~communes_df.article_id.isin(linked_places_df['article_id'])][communes_df.dpt_code != 'none']\n",
    "\n",
    "# Utiliser la colonne 'vedette' comme valeur pour la colonne 'insee_code'\n",
    "communes_fuzzy_dpt_df['insee_code'] = communes_fuzzy_dpt_df['vedette']\n",
    "\n",
    "# Pour chaque ligne dans le DataFrame \"communes_fuzzy_dpt_df\"\n",
    "for _, x in communes_fuzzy_dpt_df.iterrows():\n",
    "    # Sélectionner les valeurs de la colonne 'NCCENR' du DataFrame \"main_insee_commune\" où la colonne 'DEP_id' correspond à la valeur de la colonne 'dpt_code' de la ligne en cours (x).\n",
    "    dpt_nccenr = main_insee_commune[main_insee_commune['DEP_id'] == x['dpt_code']]['NCCENR']\n",
    "    \n",
    "    # Effectuer un fuzzy match entre les NCCENR du département et la valeur de la colonne 'vedette' de la ligne en cours (x).\n",
    "    # Sélectionner les trois meilleures correspondances (matches) ayant une similarité de 10 ou plus (selon fuzz.token_sort_ratio).\n",
    "    matches = [\n",
    "        f\"{nccenr} ({nccenr_to_insee.get(nccenr, '')}) - {main_insee_commune[main_insee_commune['NCCENR'] == nccenr]['NCCENR_orig'].iloc[0]}\"\n",
    "        for nccenr in dpt_nccenr\n",
    "        if all(word in nccenr.split() for word in x['vedette'].split()) and fuzz.token_sort_ratio(nccenr, x['vedette']) >= 10\n",
    "    ][:3]\n",
    "\n",
    "    # Mettre à jour la colonne 'insee_code' de la ligne en cours (x) avec les trois meilleures correspondances (matches).\n",
    "    communes_fuzzy_dpt_df.at[x.name, 'insee_code'] = matches\n",
    "\n",
    "# Filtrer les communes qui ont été liées avec succès (c'est-à-dire celles ayant au moins une correspondance dans la colonne 'insee_code')\n",
    "communes_fuzzy_dpt_df = communes_fuzzy_dpt_df[communes_fuzzy_dpt_df['insee_code'].map(lambda x: len(x)) > 0]\n",
    "\n",
    "# Concaténer les codes INSEE avec les NCCENR dans la même cellule, en les séparant par des virgules.\n",
    "communes_fuzzy_dpt_df['insee_code'] = communes_fuzzy_dpt_df['insee_code'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# Ajouter une colonne 'method' au DataFrame \"communes_fuzzy_dpt_df\" et définir toutes ses valeurs comme 'dpt_fuzzy'.\n",
    "communes_fuzzy_dpt_df['method'] = 'dpt_fuzzy'\n",
    "\n",
    "# Mettre à jour le DataFrame \"linked_places_df\" en y ajoutant les lignes du DataFrame \"communes_fuzzy_dpt_df\"\n",
    "# Enlever les éventuelles lignes dupliquées.\n",
    "linked_places_df = pd.concat([linked_places_df, communes_fuzzy_dpt_df]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fcf16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#méthode avec difflib\n",
    "\n",
    "'''\n",
    "import difflib\n",
    "\n",
    "# Créer un dictionnaire de correspondance entre les NCCENR et les codes INSEE\n",
    "nccenr_to_insee = main_insee_commune.set_index('NCCENR')['insee_code'].to_dict()\n",
    "\n",
    "# Lier les communes avec dpt de localisation (dpt/fuzzy match)\n",
    "communes_fuzzy_dpt_df = communes_df[~communes_df.article_id.isin(linked_places_df['article_id'])][communes_df.dpt_code != 'none']\n",
    "communes_fuzzy_dpt_df['insee_code'] = communes_fuzzy_dpt_df['vedette']\n",
    "communes_fuzzy_dpt_df['insee_code'] = communes_fuzzy_dpt_df.apply(\n",
    "    lambda x: [\n",
    "        f\"{nccenr} ({nccenr_to_insee.get(nccenr, '')}) - {main_insee_commune[main_insee_commune['NCCENR'] == nccenr]['NCCENR_orig'].iloc[0]}\"\n",
    "        for nccenr in difflib.get_close_matches(\n",
    "            x['vedette'],\n",
    "            main_insee_commune[main_insee_commune['DEP_id'] == x['dpt_code']]['NCCENR'],\n",
    "            n=3, cutoff=0.1\n",
    "        )\n",
    "        if all(word in nccenr.split() for word in x['vedette'].split())\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Sortir les communes non liées\n",
    "communes_fuzzy_dpt_df = communes_fuzzy_dpt_df[communes_fuzzy_dpt_df['insee_code'].map(lambda x: len(x)) > 0]\n",
    "\n",
    "# Concaténer les codes INSEE avec les NCCENR dans la même cellule\n",
    "communes_fuzzy_dpt_df['insee_code'] = communes_fuzzy_dpt_df['insee_code'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "communes_fuzzy_dpt_df['method'] = 'dpt_fuzzy'\n",
    "\n",
    "# Actualiser le df des liages réalisés\n",
    "linked_places_df = pd.concat([linked_places_df, communes_fuzzy_dpt_df]).drop_duplicates()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731c379f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:54:27.786460Z",
     "start_time": "2023-04-24T15:54:27.741082Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tests\n",
    "#communes_fuzzy_dpt_df.head(20)\n",
    "#linked_places_df.shape\n",
    "#linked_places_df\n",
    "communes_fuzzy_dpt_df.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3650241a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "communes_fuzzy_dpt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f8b002a-4cda-4ea9-a91d-4cd608733d51",
   "metadata": {},
   "source": [
    "### Without dpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5eea07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importer la fonction \"fuzz\" du module \"thefuzz\"\n",
    "from thefuzz import fuzz\n",
    "\n",
    "# Créer un dictionnaire de correspondance entre les NCCENR et les codes INSEE\n",
    "# À partir du DataFrame \"main_insee_commune\", utiliser la colonne 'NCCENR' comme index et la colonne 'insee_code' comme valeurs pour créer le dictionnaire.\n",
    "nccenr_to_insee = main_insee_commune.set_index('NCCENR')['insee_code'].to_dict()\n",
    "\n",
    "# Filtrer les communes sans département de localisation en utilisant des correspondances floues (fuzzy match)\n",
    "# Sélectionner les lignes du DataFrame \"communes_df\" qui ne sont pas présentes dans la colonne 'article_id' du DataFrame \"linked_places_df\"\n",
    "# et dont la valeur de la colonne 'dpt_code' est égale à 'none'.\n",
    "communes_fuzzy_nodpt_df = communes_df[~communes_df.article_id.isin(linked_places_df['article_id'])][communes_df.dpt_code == 'none']\n",
    "\n",
    "# Utiliser la colonne 'vedette' comme valeur pour la colonne 'insee_code'\n",
    "communes_fuzzy_nodpt_df['insee_code'] = communes_fuzzy_nodpt_df['vedette']\n",
    "\n",
    "# Pour chaque ligne dans le DataFrame \"communes_fuzzy_nodpt_df\"\n",
    "for _, x in communes_fuzzy_nodpt_df.iterrows():\n",
    "    # Effectuer un fuzzy match entre les NCCENR du DataFrame \"main_insee_commune\" et la valeur de la colonne 'vedette' de la ligne en cours (x).\n",
    "    # Sélectionner les trois meilleures correspondances (matches) ayant une similarité de 10 ou plus (selon fuzz.token_sort_ratio).\n",
    "    matches = [\n",
    "        f\"{nccenr} ({nccenr_to_insee.get(nccenr, '')}) - {main_insee_commune[main_insee_commune['NCCENR'] == nccenr]['NCCENR_orig'].iloc[0]}\"\n",
    "        for nccenr in main_insee_commune['NCCENR']\n",
    "        if all(word in nccenr.split() for word in x['vedette'].split()) and fuzz.token_sort_ratio(nccenr, x['vedette']) >= 10\n",
    "    ][:3]\n",
    "\n",
    "    # Mettre à jour la colonne 'insee_code' de la ligne en cours (x) avec les trois meilleures correspondances (matches).\n",
    "    communes_fuzzy_nodpt_df.at[x.name, 'insee_code'] = matches\n",
    "\n",
    "# Filtrer les communes qui ont été liées avec succès (c'est-à-dire celles ayant au moins une correspondance dans la colonne 'insee_code')\n",
    "communes_fuzzy_nodpt_df = communes_fuzzy_nodpt_df[communes_fuzzy_nodpt_df['insee_code'].map(lambda x: len(x)) > 0]\n",
    "\n",
    "# Concaténer les codes INSEE avec les NCCENR dans la même cellule, en les séparant par des virgules.\n",
    "communes_fuzzy_nodpt_df['insee_code'] = communes_fuzzy_nodpt_df['insee_code'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# Ajouter une colonne 'method' au DataFrame \"communes_fuzzy_nodpt_df\" et définir toutes ses valeurs comme 'nodpt_fuzzy'.\n",
    "communes_fuzzy_nodpt_df['method'] = 'nodpt_fuzzy'\n",
    "\n",
    "# Mettre à jour le DataFrame \"linked_places_df\" en y ajoutant les lignes du DataFrame \"communes_fuzzy_nodpt_df\"\n",
    "# Enlever les éventuelles lignes dupliquées.\n",
    "linked_places_df = pd.concat([linked_places_df, communes_fuzzy_nodpt_df]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef7d0b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#liage avec difflib\n",
    "\n",
    "'''\n",
    "import difflib\n",
    "\n",
    "# Créer un dictionnaire de correspondance entre les NCCENR et les codes INSEE\n",
    "nccenr_to_insee = main_insee_commune.set_index('NCCENR')['insee_code'].to_dict()\n",
    "\n",
    "# Lier les communes sans dpt de localisation (fuzzy match)\n",
    "communes_fuzzy_nodpt_df = communes_df[~communes_df.article_id.isin(linked_places_df['article_id'])][communes_df.dpt_code == 'none']\n",
    "communes_fuzzy_nodpt_df['insee_code'] = communes_fuzzy_nodpt_df['vedette']\n",
    "communes_fuzzy_nodpt_df['insee_code'] = communes_fuzzy_nodpt_df.apply(\n",
    "    lambda x: [\n",
    "        f\"{nccenr} ({nccenr_to_insee.get(nccenr, '')}) - {main_insee_commune[main_insee_commune['NCCENR'] == nccenr]['NCCENR_orig'].iloc[0]}\"\n",
    "        for nccenr in difflib.get_close_matches(\n",
    "            x['vedette'],\n",
    "            main_insee_commune['NCCENR'],\n",
    "            n=3, cutoff=0.1\n",
    "        )\n",
    "        if all(word in nccenr.split() for word in x['vedette'].split())\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Sortir les communes non liées\n",
    "communes_fuzzy_nodpt_df = communes_fuzzy_nodpt_df[communes_fuzzy_nodpt_df['insee_code'].map(lambda x: len(x)) > 0]\n",
    "\n",
    "# Concaténer les codes INSEE avec les NCCENR dans la même cellule\n",
    "communes_fuzzy_nodpt_df['insee_code'] = communes_fuzzy_nodpt_df['insee_code'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "communes_fuzzy_nodpt_df['method'] = 'nodpt_fuzzy'\n",
    "\n",
    "# Actualiser le df des liages réalisés\n",
    "linked_places_df = pd.concat([linked_places_df, communes_fuzzy_nodpt_df]).drop_duplicates()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f8f1c2-da57-4147-aae5-d7ce4bf58727",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:55:59.671422Z",
     "start_time": "2023-04-24T15:55:59.651488Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tests\n",
    "communes_fuzzy_nodpt_df\n",
    "#communes_fuzzy_nodpt_df.shape\n",
    "#linked_places_df.shape\n",
    "communes_fuzzy_nodpt_df.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c96835",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "communes_fuzzy_nodpt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4791c691-55a1-4d6d-b294-ed5fda26b4d7",
   "metadata": {},
   "source": [
    "## Liage des communes de localisation (fuzzy method)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b407a81-3602-4413-8317-071a47a7bfd2",
   "metadata": {},
   "source": [
    "### With dpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33597f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importer la fonction \"fuzz\" du module \"thefuzz\"\n",
    "from thefuzz import fuzz\n",
    "\n",
    "# Créer un dictionnaire de correspondance entre les NCCENR et les codes INSEE\n",
    "# À partir du DataFrame \"main_insee_commune\", utiliser la colonne 'NCCENR' comme index et la colonne 'insee_code' comme valeurs pour créer le dictionnaire.\n",
    "nccenr_to_insee = main_insee_commune.set_index('NCCENR')['insee_code'].to_dict()\n",
    "\n",
    "# Filtrer les lieux dans les communes avec département de localisation en utilisant des correspondances floues (fuzzy match)\n",
    "# Sélectionner les lignes du DataFrame \"pas_communes_df\" qui ne sont pas présentes dans la colonne 'article_id' du DataFrame \"linked_places_df\"\n",
    "# et dont la valeur de la colonne 'dpt_code' n'est pas égale à 'none'.\n",
    "pas_communes_fuzzy_dpt_df = pas_communes_df[~pas_communes_df.article_id.isin(linked_places_df['article_id'])][pas_communes_df.dpt_code != 'none']\n",
    "\n",
    "# Utiliser la colonne 'localisationco' comme valeur pour la colonne 'insee_code'\n",
    "pas_communes_fuzzy_dpt_df['insee_code'] = pas_communes_fuzzy_dpt_df['localisationco']\n",
    "\n",
    "# Pour chaque ligne dans le DataFrame \"pas_communes_fuzzy_dpt_df\"\n",
    "for _, x in pas_communes_fuzzy_dpt_df.iterrows():\n",
    "    # Sélectionner les valeurs de la colonne 'NCCENR' du DataFrame \"main_insee_commune\" où la colonne 'DEP_id' correspond à la valeur de la colonne 'dpt_code' de la ligne en cours (x).\n",
    "    dpt_nccenr = main_insee_commune[main_insee_commune['DEP_id'] == x['dpt_code']]['NCCENR']\n",
    "    \n",
    "    # Effectuer un fuzzy match entre les NCCENR du département et la valeur de la colonne 'localisationco' de la ligne en cours (x).\n",
    "    # Sélectionner les trois meilleures correspondances (matches) ayant une similarité de 10 ou plus (selon fuzz.token_sort_ratio).\n",
    "    matches = [\n",
    "        f\"{nccenr} ({nccenr_to_insee.get(nccenr, '')}) - {main_insee_commune[main_insee_commune['NCCENR'] == nccenr]['NCCENR_orig'].iloc[0]}\"\n",
    "        for nccenr in dpt_nccenr\n",
    "        if all(word in nccenr.split() for word in x['localisationco'].split()) and fuzz.token_sort_ratio(nccenr, x['localisationco']) >= 10\n",
    "    ][:3]\n",
    "\n",
    "    # Mettre à jour la colonne 'insee_code' de la ligne en cours (x) avec les trois meilleures correspondances (matches).\n",
    "    pas_communes_fuzzy_dpt_df.at[x.name, 'insee_code'] = matches\n",
    "\n",
    "# Filtrer les communes qui ont été liées avec succès (c'est-à-dire celles ayant au moins une correspondance dans la colonne 'insee_code')\n",
    "pas_communes_fuzzy_dpt_df = pas_communes_fuzzy_dpt_df[pas_communes_fuzzy_dpt_df['insee_code'].map(lambda x: len(x)) > 0]\n",
    "\n",
    "# Concaténer les codes INSEE avec les NCCENR dans la même cellule, en les séparant par des virgules.\n",
    "pas_communes_fuzzy_dpt_df['insee_code'] = pas_communes_fuzzy_dpt_df['insee_code'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# Ajouter une colonne 'method' au DataFrame \"pas_communes_fuzzy_dpt_df\" et définir toutes ses valeurs comme 'dpt_fuzzy'.\n",
    "pas_communes_fuzzy_dpt_df['method'] = 'dpt_fuzzy'\n",
    "\n",
    "# Mettre à jour le DataFrame \"linked_places_df\" en y ajoutant les lignes du DataFrame \"pas_communes_fuzzy_dpt_df\"\n",
    "# Enlever les éventuelles lignes dupliquées.\n",
    "linked_places_df = pd.concat([linked_places_df, pas_communes_fuzzy_dpt_df]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c266d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#liage avec difflib\n",
    "\n",
    "'''\n",
    "\n",
    "import difflib\n",
    "\n",
    "# Créer un dictionnaire de correspondance entre les NCCENR et les codes INSEE\n",
    "nccenr_to_insee = main_insee_commune.set_index('NCCENR')['insee_code'].to_dict()\n",
    "\n",
    "# Lier les communes avec dpt de localisation (dpt/fuzzy match)\n",
    "pas_communes_fuzzy_dpt_df = pas_communes_df[~pas_communes_df.article_id.isin(linked_places_df['article_id'])][pas_communes_df.dpt_code != 'none']\n",
    "pas_communes_fuzzy_dpt_df['insee_code'] = pas_communes_fuzzy_dpt_df['localisationco']\n",
    "pas_communes_fuzzy_dpt_df['insee_code'] = pas_communes_fuzzy_dpt_df.apply(\n",
    "    lambda x: [\n",
    "        f\"{nccenr} ({nccenr_to_insee.get(nccenr, '')}) - {main_insee_commune[main_insee_commune['NCCENR'] == nccenr]['NCCENR_orig'].iloc[0]}\"\n",
    "        for nccenr in difflib.get_close_matches(\n",
    "            x['localisationco'],\n",
    "            main_insee_commune[main_insee_commune['DEP_id'] == x['dpt_code']]['NCCENR'],\n",
    "            n=3, cutoff=0.1\n",
    "        )\n",
    "        if all(word in nccenr.split() for word in x['localisationco'].split())\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Sortir les communes non liées\n",
    "pas_communes_fuzzy_dpt_df = pas_communes_fuzzy_dpt_df[pas_communes_fuzzy_dpt_df['insee_code'].map(lambda x: len(x)) > 0]\n",
    "\n",
    "# Concaténer les codes INSEE avec les NCCENR dans la même cellule\n",
    "pas_communes_fuzzy_dpt_df['insee_code'] = pas_communes_fuzzy_dpt_df['insee_code'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "pas_communes_fuzzy_dpt_df['method'] = 'dpt_fuzzy'\n",
    "\n",
    "# Actualiser le df des liages réalisés\n",
    "linked_places_df = pd.concat([linked_places_df, pas_communes_fuzzy_dpt_df]).drop_duplicates()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b189b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:58:41.462084Z",
     "start_time": "2023-04-24T15:58:41.398818Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tests\n",
    "pas_communes_fuzzy_dpt_df\n",
    "#linked_places_df.shape\n",
    "#linked_places_df\n",
    "pas_communes_fuzzy_dpt_df.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed8e6ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pas_communes_fuzzy_dpt_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d1170a-b328-4170-b849-0c77852a0203",
   "metadata": {},
   "source": [
    "### Without dpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e707a36",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importer la fonction \"fuzz\" du module \"thefuzz\"\n",
    "from thefuzz import fuzz\n",
    "\n",
    "# Créer un dictionnaire de correspondance entre les NCCENR et les codes INSEE\n",
    "# À partir du DataFrame \"main_insee_commune\", utiliser la colonne 'NCCENR' comme index et la colonne 'insee_code' comme valeurs pour créer le dictionnaire.\n",
    "nccenr_to_insee = main_insee_commune.set_index('NCCENR')['insee_code'].to_dict()\n",
    "\n",
    "# Filtrer les lieux dans les communes sans département de localisation en utilisant des correspondances floues (fuzzy match)\n",
    "# Sélectionner les lignes du DataFrame \"pas_communes_df\" qui ne sont pas présentes dans la colonne 'article_id' du DataFrame \"linked_places_df\"\n",
    "# et dont la valeur de la colonne 'dpt_code' est égale à 'none'.\n",
    "pas_communes_fuzzy_nodpt_df = pas_communes_df[~pas_communes_df.article_id.isin(linked_places_df['article_id'])][pas_communes_df.dpt_code == 'none']\n",
    "\n",
    "# Utiliser la colonne 'localisationco' comme valeur pour la colonne 'insee_code'\n",
    "pas_communes_fuzzy_nodpt_df['insee_code'] = pas_communes_fuzzy_nodpt_df['localisationco']\n",
    "\n",
    "# Pour chaque ligne dans le DataFrame \"pas_communes_fuzzy_nodpt_df\"\n",
    "for _, x in pas_communes_fuzzy_nodpt_df.iterrows():\n",
    "    # Effectuer un fuzzy match entre les NCCENR du DataFrame \"main_insee_commune\" et la valeur de la colonne 'localisationco' de la ligne en cours (x).\n",
    "    # Sélectionner les trois meilleures correspondances (matches) ayant une similarité de 10 ou plus (selon fuzz.token_sort_ratio).\n",
    "    matches = [\n",
    "        f\"{nccenr} ({nccenr_to_insee.get(nccenr, '')}) - {main_insee_commune[main_insee_commune['NCCENR'] == nccenr]['NCCENR_orig'].iloc[0]}\"\n",
    "        for nccenr in main_insee_commune['NCCENR']\n",
    "        if all(word in nccenr.split() for word in x['localisationco'].split()) and fuzz.token_sort_ratio(nccenr, x['localisationco']) >= 10\n",
    "    ][:3]\n",
    "\n",
    "    # Mettre à jour la colonne 'insee_code' de la ligne en cours (x) avec les trois meilleures correspondances (matches).\n",
    "    pas_communes_fuzzy_nodpt_df.at[x.name, 'insee_code'] = matches\n",
    "\n",
    "# Filtrer les communes qui ont été liées avec succès (c'est-à-dire celles ayant au moins une correspondance dans la colonne 'insee_code')\n",
    "pas_communes_fuzzy_nodpt_df = pas_communes_fuzzy_nodpt_df[pas_communes_fuzzy_nodpt_df['insee_code'].map(lambda x: len(x)) > 0]\n",
    "\n",
    "# Concaténer les codes INSEE avec les NCCENR dans la même cellule, en les séparant par des virgules.\n",
    "pas_communes_fuzzy_nodpt_df['insee_code'] = pas_communes_fuzzy_nodpt_df['insee_code'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "# Ajouter une colonne 'method' au DataFrame \"pas_communes_fuzzy_nodpt_df\" et définir toutes ses valeurs comme 'nodpt_fuzzy'.\n",
    "pas_communes_fuzzy_nodpt_df['method'] = 'nodpt_fuzzy'\n",
    "\n",
    "# Mettre à jour le DataFrame \"linked_places_df\" en y ajoutant les lignes du DataFrame \"pas_communes_fuzzy_nodpt_df\"\n",
    "# Enlever les éventuelles lignes dupliquées.\n",
    "linked_places_df = pd.concat([linked_places_df, pas_communes_fuzzy_nodpt_df]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13411397",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#liage avec difflib\n",
    "\n",
    "import difflib\n",
    "\n",
    "# Créer un dictionnaire de correspondance entre les NCCENR et les codes INSEE\n",
    "nccenr_to_insee = main_insee_commune.set_index('NCCENR')['insee_code'].to_dict()\n",
    "\n",
    "# Lier les communes sans dpt de localisation (fuzzy match)\n",
    "pas_communes_fuzzy_nodpt_df = pas_communes_df[~pas_communes_df.article_id.isin(linked_places_df['article_id'])][pas_communes_df.dpt_code == 'none']\n",
    "pas_communes_fuzzy_nodpt_df['insee_code'] = pas_communes_fuzzy_nodpt_df['localisationco']\n",
    "pas_communes_fuzzy_nodpt_df['insee_code'] = pas_communes_fuzzy_nodpt_df.apply(\n",
    "    lambda x: [\n",
    "        f\"{nccenr} ({nccenr_to_insee.get(nccenr, '')}) - {main_insee_commune[main_insee_commune['NCCENR'] == nccenr]['NCCENR_orig'].iloc[0]}\"\n",
    "        for nccenr in difflib.get_close_matches(\n",
    "            x['localisationco'],\n",
    "            main_insee_commune['NCCENR'],\n",
    "            n=3, cutoff=0.1\n",
    "        )\n",
    "        if all(word in nccenr.split() for word in x['localisationco'].split())\n",
    "    ],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Sortir les communes non liées\n",
    "pas_communes_fuzzy_nodpt_df = pas_communes_fuzzy_nodpt_df[pas_communes_fuzzy_nodpt_df['insee_code'].map(lambda x: len(x)) > 0]\n",
    "\n",
    "# Concaténer les codes INSEE avec les NCCENR dans la même cellule\n",
    "pas_communes_fuzzy_nodpt_df['insee_code'] = pas_communes_fuzzy_nodpt_df['insee_code'].apply(lambda x: ', '.join(x))\n",
    "\n",
    "pas_communes_fuzzy_nodpt_df['method'] = 'nodpt_fuzzy'\n",
    "\n",
    "# Actualiser le df des liages réalisés\n",
    "linked_places_df = pd.concat([linked_places_df, pas_communes_fuzzy_nodpt_df]).drop_duplicates()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b49e255",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pas_communes_fuzzy_nodpt_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80f0333",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T15:58:56.248887Z",
     "start_time": "2023-04-24T15:58:56.234495Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tests\n",
    "pas_communes_fuzzy_nodpt_df\n",
    "#linked_places_df.shape\n",
    "pas_communes_fuzzy_nodpt_df.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439698ed-ef4d-4ada-8d03-13d09bef32c4",
   "metadata": {},
   "source": [
    "# Postprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7170c9-5b95-4a96-a559-5887027b8892",
   "metadata": {},
   "source": [
    "## Rapport et analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b523c4ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T16:21:14.537189Z",
     "start_time": "2023-04-24T16:21:14.496792Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# On crée un DataFrame new_rows_df en filtrant les lignes de df qui ne sont pas présentes dans linked_places_df\n",
    "new_rows_df = df[~df['article_id'].isin(linked_places_df['article_id'])]\n",
    "\n",
    "# On vérifie si 'method' n'est pas dans les colonnes de new_rows_df\n",
    "if 'method' not in new_rows_df.columns:\n",
    "    new_rows_df['method'] = 'nulle'\n",
    "\n",
    "# On utilise la méthode .concat pour ajouter les lignes de new_rows_df à linked_places_df\n",
    "linked_places_df = pd.concat([linked_places_df, new_rows_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499ae5d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linked_places_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bef479",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linked_places_df.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba8a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# des doublons?\n",
    "nombre_de_doublons = linked_places_df.duplicated(subset=['article_id']).sum()\n",
    "print(nombre_de_doublons)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57491e63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "linked_places_df.loc[linked_places_df.duplicated(keep=False,subset=['article_id']), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "540cff26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T16:21:33.554226Z",
     "start_time": "2023-04-24T16:21:33.537360Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "method_counts = linked_places_df['method'].value_counts()\n",
    "print(method_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5951adf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-24T16:24:15.973479Z",
     "start_time": "2023-04-24T16:24:15.618078Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vedette_list = pd.unique(linked_places_df['vedette'])\n",
    "linked_places_df['sort_key'] = linked_places_df.apply(lambda x: x['localisationco'] if x['localisationco'] in vedette_list else x['vedette'], axis=1)\n",
    "linked_places_df.sort_values(['method', 'sort_key', 'article_id'], inplace=True)\n",
    "linked_places_df = linked_places_df.drop('sort_key', axis=1)\n",
    "linked_places_df = linked_places_df[['article_id', 'vedette', 'vedette_orig', 'localisationde', 'dpt_code', 'canton_code', 'localisationco', 'localisationco_orig', 'NCCENR_orig', 'insee_code', 'method', 'reference']]\n",
    "linked_places_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b333681",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empty_rows = linked_places_df[linked_places_df['vedette'] == '']\n",
    "empty_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d42271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "empty_rows.agg(['nunique', 'count', 'size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec412f07-9349-4232-8f10-af828eab4420",
   "metadata": {},
   "source": [
    "## Export\n",
    "\n",
    "Suite à tous nos traitements, nous exportons le résultat sous la forme d'un fichier CSV. \n",
    "\n",
    "Il prend cette forme;\n",
    "\n",
    "article_id: id du pouillé\n",
    "\n",
    "vedette: vedette du pouillé, traitée (donc sans ponctuation ni mots jugés 'dérangeants' au liage)\n",
    "\n",
    "vedette_orig: vedette au format originel\n",
    "\n",
    "localisationde: département\n",
    "\n",
    "dpt_code: code du département\n",
    "\n",
    "canton_code: canton\n",
    "\n",
    "localisationco: pour les lieux dans des communes, localisationco du pouillé, traité (donc sans ponctuation ni mots jugés 'dérangeants' au liage)\n",
    "\n",
    "localisationco_orig: localisationco au format originel\n",
    "\n",
    "nccenr_orig: le nccenr originel du référentiel insee (uniquement pour les exact matches)\n",
    "\n",
    "insee_code: le code insee. Pour les fuzzy, il y a le nccenr originel + nettoyé + le code insee pour chaque proposition; pour faciliter la correction d'Olivier\n",
    "\n",
    "method: la méthode effectuée. Il y en a 7 en principe (à part si nous avons une absence de résultat pour la méthode): dpt_exact, nodpt_exact (methode exact match 1), dpt_exact_simple, no_dpt_exact_simple (method exact match 2), dpt_fuzzy, nodpt_fuzzy, nulle (lorsque nous n'avons pas pu faire le liage)\n",
    "\n",
    "reference: tout le texte de chaque article pouillé\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3b161f-cf40-43da-8b56-ee697587d6ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sauvegarder le dataframe fusionné\n",
    "linked_places_df.to_csv('../../utils/pouille/out/linking_out/liage_po11.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86debfab",
   "metadata": {},
   "source": [
    "# Note – réflexions sur le fuzzy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e9630c",
   "metadata": {},
   "source": [
    "Après avoir effectué des tests, on se rend compte qu'il y a plusieurs incohérences.\n",
    "\n",
    "1. Difflib, avec main_insee_commune, n'arrive pas à lier certains cas en fuzzy (par exemple, Deneuille & Deneuille-lès-Chantelle). Pourtant, difflib y arrive lorsqu'il utilise un fichier txt de base. Peut-être un souci au niveau de main_insee_commune ? A verifier.\n",
    "\n",
    "2. Au contraire, TheFuzz arrive à lier dans les deux cas: super. Par contre, il lie des choses en plus (Hures) avec main_insee_commune, mais pas avec le fichier txt. A verifier sur main_insee_commune: il ne semble pourtant pas y avoir d'espace ou de lettres en plus ou en moins.\n",
    "\n",
    "Pour l'instant, nous gardons thefuzz, mais nous sauvegardons tous les codes de difflib en bas du notebook au cas où, comme les deux manières de faire semblent un peu faillibles (en attendant de comprendre)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
